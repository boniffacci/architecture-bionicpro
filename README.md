# Задание спринта 9

## Задание 1. Повышение безопасности системы

### Задача 1. Предложите архитектурное решение и доработайте диаграмму C4 для управления учётными данными пользователя. 

Решение должно учитывать и обеспечивать следующие аспекты:

- Унификацию доступа в системе BionicPRO. Это будет осуществляться через запрос данных учётных записей из внешнего источника, который расположен в стране представительства компании. Принципы локального хранения персональной и медицинской информации не должны быть нарушены.
- Безопасную схему работы с access- и refresh-токенами, которая исключает передачу фронтенду токенов, которые были получены от IdP.
- Возможность поддержки аутентификации пользователей через различные внешние удостоверяющие службы, действующие в разных странах.

Доработанная диаграмма C4 представлена в файле `task1/task1_BionicPRO_C4_model.drawio.xml` (подкаталог task1) и [для удобства в файле `task1/task1_BionicPRO_C4_model.png`.](./task1/task1_BionicPRO_C4_model.png)

На диаграмму добавлены:

- Auth Service (BFF) - шлюз авторизации.
- Regional Identity Provider - внешний провайдер аутентификации.
- ClickHouse - аналитическое хранилище для телеметрии.
- Report Service - сервис генерации отчетов.

### Задача 2. Улучшите безопасность существующего приложения, заменив Code Grant на PKCE. 
Его нужно добавить к уже существующим приложениям — фронтенду и Keycloak. 

Для перевода приложения PKCE (Proof Key for Code Exchange) необходимо внести изменения в конфигурацию Keycloak (серверная часть) и в инициализацию клиента Keycloak в React-приложении.

Изменения вносятся в файлы:

1. Keycloak (realm-export.json):

- Для клиента reports-frontend необходимо отключить implicitFlowEnabled (устаревший и небезопасный для SPA).
- Необходимо отключить directAccessGrantsEnabled (вход по логину/паролю без браузерного редиректа), так как это увеличивает риск фишинга.
- Необходимо включить standardFlowEnabled.
- Необходимо добавить атрибут pkce.code.challenge.method: S256, чтобы сервер Keycloak требовал наличие PKCE при обмене кодами.

2. Frontend (src/App.tsx):

- Необходимо изменить параметры инициализации провайдера ReactKeycloakProvider.
- Добавить pkceMethod: 'S256', чтобы библиотека keycloak-js автоматически генерировала code_verifier и  code_challenge перед отправкой пользователя на страницу входа.


#### Проверим работоспособность и безопасность приложения.

1. Запустим Docker Compose 

`docker-compose up --build`

[Скриншот с результатом успешного выполнения.](./task1/screens/1.png)

2. Откроем веб-интерфейс по адресу `http://localhost:3000`

[Скриншот с результатом успешного выполнения.](./task1/screens/2.png)

3. Нажмем кнопку логина, в результате чего произойдет переадресация на форму ввода имени пользователя и пароля.

[Скриншот с результатом успешного выполнения.](./task1/screens/3.png)

4. Зайдем под пользователем `user1/password123`

На скриншоте видны заголовки POST-запроса, характерные для PKCE, в частности code_verifier.

[Скриншот с результатом успешного выполнения.](./task1/screens/4.png)

[Еще один скриншот с refresh_token.](./task1/screens/5.png)

5. Откроем административную панель Keycloak по адресу `http://localhost:8080`.

Убедимся, что Keycloak требует PKCE для reports-frontend.

[Скриншот 1 - вкладка Settings.](./task1/screens/6.png)

- Client authentication: выключена
- Standard flow: включена
- Implicit flow: выключена
- Direct access grants: выключена, пароли не передаются напрямую

[Скриншот 2 - вкладка Advanced.](./task1/screens/7.png)

- Proof Key for Code Exchange Code Challenge Method: S256

#### Таким образом, проведена замена Code Grant на PKCE.

## Задание 2. Разработка сервиса отчетов

### Задача 1. Создать архитектуру решения для подготовки и получения отчетов.

Решение должно включать в себя ETL-процесс, который объединяет данные с датчиков и данные из CRM, используя Apache Airflow, и формирует готовую витрину отчётности в OLAP БД. Итоговый отчёт по пользователю должен быть доступен через бэкенд-сервис API, который обозначен на исходной архитектуре. 
Для подготовки архитектуры решения используйте draw.io.

Разработанная диаграмма C4 представлена в файле `task2/task2_model.drawio.xml` (подкаталог task2) и [для удобства в файле `task2/task2_model.png`.](./task2/task2_model.png)

### Задача 2. Разработать Airflow DAG и настроить его на запуск по расписанию.

- Реализуйте ETL-процесс с использованием Airflow, который будет извлекать данные из CRM-системы и записывать их в базу OLAP.
- Подготовьте витрину — отдельную таблицу для сервиса отчётов, в которой вам предстоит объединить данные телеметрии и данные о клиентах из CRM-системы. Для этого нужно будет сгруппировать аналитику по телеметрии в разрезе клиентов. Спроектируйте структуру витрины таким образом, чтобы обеспечить быстрый доступ к данным по пользователям. За основу при написании DAG можно взять материал уроков спринта.
- Настройте расписание сбора данных и подготовки витрины.

#### Шаг 1. Создание SQL-файлов для CRM и OLAP. 

Создадим в проекте каталог `sql`, в котором создадим файлы `init_crm.sql` для инициализации CRM и файл  `init_clickhouse.sql` для инициализации OLAP. 

Здесь и далее содержимое создаваемых файлов находится непосредственно в файлах и в README не приводится.

Файл `init_crm.sql` содержит пользователей, которые точно совпадают с конфигурацией Keycloak.

#### Шаг 2. Создание Airflow DAG. 

Разместим решение в каталоге проекта `airflow`.

Создадим `Dockerfile` для развертывания Airflow.

Создадим подкаталог `dags` и в нем файл DAG `etl_crm_to_olap.py`.

При запуске DAG в параметре schedule_interval задается [CRON-выражение.](https://yandex.cloud/ru/docs/serverless-integrations/concepts/cron) таким образом выполняется требование запуска по расписанию.


#### Шаг 3. Внесение изменений в docker-compose.yaml для запуска Airflow, CRM, OLAP.

В проекте представлен измененный файл `docker-compose.yaml`.

#### Шаг 4. Проверка работы Airflow DAG. 

1. Запустим Docker Compose 

`docker-compose up --build`

2. DAG будет выполнен. 

Первые три запуска, соответствующие отладке DAG были неуспешными, последний запуск успешен.

[Скриншот с результатом успешного выполнения DAG.](./task2/screens/2_1.png)

[Скриншот с результатом успешного запроса в OLAP по результатам выполнения DAG.](./task2/screens/2_2.png)

### Задача 3. Создайте бэкенд-часть приложения для API.

    
    Добавьте API /reports в этот бэкенд для передачи отчётов, который будет возвращать подготовленный отчёт по заданному пользователю. Отчёт должен запрашиваться из OLAP-базы без необходимости выполнять сложные вычисления в реальном времени.

Будем использовать Python и FastAPI.

Создадим в проекте каталог `backend`, в котором создадим файлы `requirements.txt`, `main.py` и `Dockerfile`. 

Данные о сервисе `backend` добавляются в `docker-compose.yaml`.


### Задача 4. Реализуйте ограничение доступа к эндпоинту отчётности.

    Доступ к отчёту по пользователю должен предоставляться только в отношении себя. 

Это требование реализовано на уровне бэкенда (backend/main.py) с использованием комбинации JWT-токена и SQL-фильтрации следующим образом:

- Нет параметров в URL: Пользователь не передает свой ID в адресе запроса (например, GET /reports?user=user1). Если бы он передавал, он мог бы подменить user1 на user2.

- Источником данных является токен. Идентификатор пользователя берется только из зашифрованного токена.

- Фильтрация в SQL-запросе. Запрос не может вернуть строки, где keycloak_username не совпадает с тем, кто пришел в токене.

Таким образом, даже если user1 очень захочет получить данные user2, он не сможет этого сделать, потому что сервер выполнит запрос: SELECT ... WHERE keycloak_username = 'user1' (где 'user1' взято из токена), и база данных просто не вернет чужие записи.

### Задача 5. Добавьте в UI кнопку получения отчёта и вызова эндпоинта его генерации.

Компонент `frontend/src/components/ReportPage.tsx` изменен таким образом, чтобы обращаться к API и отображать таблицу.


### Проведем финальное тестирование в соответствии с заданием:


#### Тест 1. UI-код позволяет вызвать API для генерации отчётов.

1. Откроем веб-интерфейс по адресу `http://localhost:3000`

2. Зайдем под пользователем `user1/password123`. Нажмем кнопку "Get My Reports".

3. В просмотре сетевых соединений виден запрос GET http://localhost:8000/reports со статусом 200. В интерфейсе отобразилась таблица с данными.

[Скриншот с результатом успешного выполнения.](./task2/screens/5_1.png)

#### Тест 2. Реализация не позволяет генерировать отчёт пользователю, который не прошёл аутентификацию.

Попытаемся сделать запрос к API без токена:

`curl -v http://localhost:8000/reports`

Ответ сервера - 401 Unauthorized.

[Скриншот с результатом успешного выполнения.](./task2/screens/5_2.png)

#### Тест 3. Реализация позволяет генерировать авторизованному пользователю только собственный отчёт.

В тесте 1 возвращались данные только для первого пользователя.

Если нажать ссылку logout и войти вторым пользователем, то отбразатся только данные для второго пользователя `user2/password123`. 

[Скриншот с результатом успешного выполнения.](./task2/screens/5_3.png)

#### Тест 4. Добавили в сервис отчётов их генерацию по запросу пользователя из OLAP: приложение должно отправлять запросы в OLAP базу для получения отчётов.

Выполним команду:

`docker-compose exec clickhouse clickhouse-client --query "SELECT * FROM system.query_log ORDER BY event_time DESC LIMIT 1"`

Последним действительно выполнялся запрос для пользователя user2, который был выполнен в предыдущем пункте.

[Скриншот с результатом успешного выполнения.](./task2/screens/5_4.png)

#### Тест 5. Предусмотрели генерацию отчётов только за период, который уже обработан Airflow. Обратите внимание, что пользователь может запросить данные, которых ещё нет в OLAP.

- Бэкенд делает SELECT из таблицы report_user_daily_mart. 
- Эта таблица заполняется только когда отрабатывает Airflow DAG.
- Если пользователь запросит данные за будущий период или за текущий момент, который еще не попал в выгрузку, то он просто не увидит этих строк в таблице, так как их физически нет в витрине. 
- API не обращается к сырым данным и не делает расчеты на лету.
